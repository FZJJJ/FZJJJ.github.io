---

layout: post

title: 邱锡鹏《神经网络与深度学习》01

categories: [blog]

tags: [deeplearning]

description: 

---



此系列博客来源于邱锡鹏教授的《神经网络与深度学习》一书，在学习此书的同时，写一点东西加深记忆，同时也是为了夏令营做准备（老师的唯一指定复习书籍）。本书主要分为三个pt，机器学习基础、基础模型与进阶模型，后续将每章写一篇博文。



## chapter1 绪论

深度学习实际上就是借助一个模型，该模型包含若干线性或非线性的组件，对模型的训练便是在改变各个组件的参数，调整它们的贡献度，即所谓的**贡献度分配（CAP）**。其中比较好解决CAP的模型就是**人工神经网络（ANN）**。因为ANN一般比较复杂，层数很多，因此对此模型的机器学习就称为**深度学习**，这也就是为什么深度学习总是与神经网络绑定，但是并非一个概念。



#### 1.1 人工智能（AI）

即让机器的行为看起来像是人所表现出来的智能行为一样。

主要领域：

- 感知：语音信息处理、计算机视觉
- 学习：监督、无监督的学习、强化学习
- 认知：知识表示、自然语言理解、推理、决策、规划



发展历史：

1. 推理期
2. 知识期
3. 学习期



流派：

- 符号主义：逻辑主义、心理学派或计算学派。即分析人类的智能，后用计算机实现功能，优点是可解释性。
- 连接主义：仿生学派或生理学派。大量简单信息处理单元组成的互联网络，具有非线性、分布式、并行化、局部性计算以及自适应性。



#### 1.2 机器学习

从有限的观测数据中，学习或猜测出一般性的规律，并利用规律对未知数据进行预测。

主要步骤：

1. 数据预处理：即构建可用的数据集（特征缩放、归一化）
2. 特征提取：提取对于任务有用的高质量特征
3. 特征转换：降维或升维。降维包括特征抽取、特征选择。常用方法有主成分分析（PCA）、线性判别分析（LDA）
4. 预测：核心的部分，学习函数并进行预测

一般地，特征工程往往在机器学习中最为重要（前三步）。



#### 1.3 表示学习

自动学习出有效的特征，并提高最终机器学习模型的性能。其关键在于解决**语义鸿沟（Semantic Gap）**问题，即输入数据的底层特征和高层语义信息之间的不一致性与差异性。



- 局部表示：稀疏向量，如one-hot编码：很好的解释性，但是维数很高且无法拓展
- 分布式表示：稠密向量，如RGB表示颜色，表示能力更强，且维数低



#### 1.4 深度学习

除去和一般机器学习一样的表示学习，还会进行深度学习，而非“浅层学习”，并一般使用神经网络模型，采用误差反向传播算法（BP）来解决CAP问题。目前大部分NN模型都采用**端到端学习**，不需明确各阶段的功能，只专注于输入-输出对。



#### 1.5 神经网络

后续有详细说明。

发展历史：

1. 模型提出：1943～1969
2. 冰河期：1969～1983
3. 反响传播算法引起的复兴：1983～1995
4. 流行度降低：1995～2006
5. 深度学习的崛起：2006～至今



#### 1.6 本书知识体系

po一张图

![](https://typora-fzj.oss-cn-qingdao.aliyuncs.com/%E6%88%AA%E5%B1%8F2022-07-03%2016.00.21.png)

#### 1.7 常用的深度学习框架

Theano、Caffe、**Tensorflow、Pytorch**、飞浆（PaddlePaddle）、Chainer、MXNet等